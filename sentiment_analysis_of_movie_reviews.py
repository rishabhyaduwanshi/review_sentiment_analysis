# -*- coding: utf-8 -*-
"""sentiment_analysis_of_movie_reviews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BauzgFhGgY60uw3xJajerbMjSfMZ54HQ

# This project deals in sentiment analysis

```
# This project is made with the help of already existing lectures over the internet
'and holds the sole purpose of learning NLP and ML'
 i in any form do not claim to generate anything new but assures that i have understood the approach and methodolgy used in it
```
"""

import numpy as np
import pandas as pd
import re
#module for visualization
import matplotlib.pyplot as plt
import seaborn as sb
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn import tree
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
#Tools for preprocessing input data
from bs4 import BeautifulSoup
from nltk import word_tokenize
from nltk.corpus import stopwords
import nltk
from sklearn.feature_extraction.text import CountVectorizer
from nltk.stem.porter import PorterStemmer
from nltk.stem import WordNetLemmatizer
import gensim
nltk.download('stopwords')

data=pd.read_csv('https://raw.githubusercontent.com/prateek22sri/Sentiment-analysis/master/labeledTrainData.tsv',delimiter="\t")

data.shape

data=data[:2000]

data.describe()

data=data.drop(["id"],axis=1)

data.head()

"""This section involves data PreProcessing"""

def processing(review):
  # Remove email address with 'emailaddr'
  raw_review=re.sub('\b[\w\-.]+?@\w+?\.\w{2,4}\b'," ",review)
  # Remove URLs with 'httpaddr'
  raw_review=re.sub('(http[s]?\S+) | (\w+\.[A-Za-z]{2,4}\S*)'," ",raw_review)
  # Remove non-letters
  raw_review=re.sub("[^a-zA-Z]"," ",raw_review)
  # Remove numbers
  raw_review=re.sub('\d+(\.\d+)?'," ",raw_review)
  words=raw_review.lower().split()
  stop=set(stopwords.words("english"))
  meaningful_words=[ps.stem(w) for w in words if not w in stop]
  return (" ".join(meaningful_words))

clean_review_corpus=[]
ps=PorterStemmer()

review_count=data['review'].size
review_count



for i in range(0,review_count):
  clean_review_corpus.append(processing(data["review"][i]))

data["review"][0]

clean_review_corpus[0]

cv=CountVectorizer()
data_input=cv.fit_transform(clean_review_corpus)
data_input=data_input.toarray()

"""creating wordcloud

"""

from wordcloud import WordCloud,STOPWORDS

stopwords=set(STOPWORDS)

def show_wordcloud(data,title=None):
  wordcloud=WordCloud(background_color='black',stopwords=stopwords,max_words=200,max_font_size=40,scale=3,random_state=1).generate(str(data))
  fig=plt.figure(1,figsize=(15,15))
  plt.axis("off")
  if title:
    fig.subplot(title,fontsize=20)
    fig.subplots_adjust(top=2.3)
  plt.imshow(wordcloud)  
  plt.show()

show_wordcloud(clean_review_corpus) #selects the top 200 frequent words



"""# <font color='green'>Applying Classification</font>

* <b>input</b>=prepare sparse matrix/Vector for each message
* <b>output</b>=Negative or Positive sentiment
"""

data_output=data['sentiment']

data_output.value_counts().plot.bar()

"""Splitting data for Training and Testing"""

from sklearn.model_selection import train_test_split
train_x,test_x,train_y,test_y=train_test_split(data_input,data_output,test_size=0.20,random_state=0)

"""Training"""

model_nvb=GaussianNB()
model_nvb.fit(train_x,train_y)
model_rf=RandomForestClassifier(n_estimators=1000,random_state=0)
model_rf.fit(train_x,train_y)
model_dt=tree.DecisionTreeClassifier()
model_dt.fit(train_x,train_y)

"""prediction"""

prediction_nvb=model_nvb.predict(test_x)
prediction_rf=model_rf.predict(test_x)
prediction_dt=model_dt.predict(test_x)

"""#Result Naive Bayes"""

print("Accuracy for Naive Bayes: %0.5f\n\n" % accuracy_score(test_y,prediction_nvb))
print("Classification Report Naive bayes: \n",classification_report(test_y,prediction_nvb))

"""#Result Decision Tree"""

print("Accuracy for Decision Tree: %0.5f\n\n" % accuracy_score(test_y,prediction_dt))
print("Classification Report Decision Tree: \n",classification_report(test_y,prediction_dt))

"""#Result Random Forest"""

print("Accuracy for Random Forest: %0.5f\n\n" % accuracy_score(test_y,prediction_rf))
print("Classification Report Random Forest: \n",classification_report(test_y,prediction_rf))

